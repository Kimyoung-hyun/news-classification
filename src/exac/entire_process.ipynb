{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cbacdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/yhkim/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import \n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "from collections import Counter\n",
    "import torch.optim as optim\n",
    "import html\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da657b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "def set_seed(seed_value):\n",
    "    random.seed(seed_value)  # 파이썬 난수 생성기\n",
    "    np.random.seed(seed_value)  # Numpy 난수 생성기\n",
    "    torch.manual_seed(seed_value)  # PyTorch 난수 생성기\n",
    "\n",
    "    # CUDA 환경에 대한 시드 설정 (GPU 사용 시)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "SEED = 42\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa23b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 불러오기\n",
    "train_df = pd.read_csv('../../data/train.csv') \n",
    "test_df = pd.read_csv('../../data/test.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8cff57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   Class Index  120000 non-null  int64 \n",
      " 1   Title        120000 non-null  object\n",
      " 2   Description  120000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a9e996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new column 추가 title + description\n",
    "train_df['text'] = train_df['Title'] + \" \" + train_df['Description']\n",
    "\n",
    "train_df['text'].head(10)\n",
    "\n",
    "test_df['text'] = test_df['Title'] + \" \" + test_df['Description']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df2bb916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    120000.000000\n",
       "mean        236.460025\n",
       "std          66.529799\n",
       "min          17.000000\n",
       "25%         196.000000\n",
       "50%         232.000000\n",
       "75%         266.000000\n",
       "max        1012.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리 전 길이 확인\n",
    "train_df['text'].str.len().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f4f6b",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4c31db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71787</th>\n",
       "      <td>3</td>\n",
       "      <td>BBC set for major shake-up, claims newspaper</td>\n",
       "      <td>London - The British Broadcasting Corporation, the world #39;s biggest public broadcaster, is to cut almost a quarter of its 28 000-strong workforce, in the biggest shake-up in its 82-year history, The Times newspaper in London said on Monday.</td>\n",
       "      <td>BBC set for major shake-up, claims newspaper London - The British Broadcasting Corporation, the world #39;s biggest public broadcaster, is to cut almost a quarter of its 28 000-strong workforce, in the biggest shake-up in its 82-year history, The Times newspaper in London said on Monday.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67218</th>\n",
       "      <td>3</td>\n",
       "      <td>Marsh averts cash crunch</td>\n",
       "      <td>Embattled insurance broker #39;s banks agree to waive clause that may have prevented access to credit. NEW YORK (Reuters) - Marsh  amp; McLennan Cos.</td>\n",
       "      <td>Marsh averts cash crunch Embattled insurance broker #39;s banks agree to waive clause that may have prevented access to credit. NEW YORK (Reuters) - Marsh  amp; McLennan Cos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54066</th>\n",
       "      <td>2</td>\n",
       "      <td>Jeter, Yankees Look to Take Control (AP)</td>\n",
       "      <td>AP - Derek Jeter turned a season that started with a terrible slump into one of the best in his accomplished 10-year career.</td>\n",
       "      <td>Jeter, Yankees Look to Take Control (AP) AP - Derek Jeter turned a season that started with a terrible slump into one of the best in his accomplished 10-year career.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7168</th>\n",
       "      <td>4</td>\n",
       "      <td>Flying the Sun to Safety</td>\n",
       "      <td>When the Genesis capsule comes back to Earth with its samples of the sun, helicopter pilots will be waiting for it, ready to snag it out of the sky.</td>\n",
       "      <td>Flying the Sun to Safety When the Genesis capsule comes back to Earth with its samples of the sun, helicopter pilots will be waiting for it, ready to snag it out of the sky.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29618</th>\n",
       "      <td>3</td>\n",
       "      <td>Stocks Seen Flat as Nortel and Oil Weigh</td>\n",
       "      <td>NEW YORK (Reuters) - U.S. stocks were set to open near  unchanged on Thursday after a warning from technology  bellwether Nortel Networks Corp. &amp;lt;A HREF=\"http://www.investor.reuters.com/FullQuote.aspx?ticker=NT.N target=/stocks/quickinfo/fullquote\"&amp;gt;NT.N&amp;lt;/A&amp;gt; dimmed hopes, while  stubbornly high oil prices also weighed on sentiment.</td>\n",
       "      <td>Stocks Seen Flat as Nortel and Oil Weigh  NEW YORK (Reuters) - U.S. stocks were set to open near  unchanged on Thursday after a warning from technology  bellwether Nortel Networks Corp. &amp;lt;A HREF=\"http://www.investor.reuters.com/FullQuote.aspx?ticker=NT.N target=/stocks/quickinfo/fullquote\"&amp;gt;NT.N&amp;lt;/A&amp;gt; dimmed hopes, while  stubbornly high oil prices also weighed on sentiment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101425</th>\n",
       "      <td>2</td>\n",
       "      <td>Inter Milan seeks redemption win against Juventus</td>\n",
       "      <td>It is early in the season for a decisive match, yet Inter Milan-Juventus on Sunday is shaping up as exactly that. Serie A leader Juventus stands 15 points ahead of Inter, but both teams see the meeting as key to their season.</td>\n",
       "      <td>Inter Milan seeks redemption win against Juventus It is early in the season for a decisive match, yet Inter Milan-Juventus on Sunday is shaping up as exactly that. Serie A leader Juventus stands 15 points ahead of Inter, but both teams see the meeting as key to their season.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20441</th>\n",
       "      <td>3</td>\n",
       "      <td>Saudi Arabia cuts oil prices</td>\n",
       "      <td>Oil prices eased yesterday as top world exporter Saudi Arabia slashed prices for its westbound crude sales in an effort to shift the large volumes it is offering to cool world markets.</td>\n",
       "      <td>Saudi Arabia cuts oil prices Oil prices eased yesterday as top world exporter Saudi Arabia slashed prices for its westbound crude sales in an effort to shift the large volumes it is offering to cool world markets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2662</th>\n",
       "      <td>1</td>\n",
       "      <td>Google Cuts Its IPO Price Range</td>\n",
       "      <td>SAN JOSE, Calif. - In a sign that Google Inc.'s initial public offering will not be as hot or big as expected, the Internet search giant slashed its estimated per-share price range and reduced the number of shares to be sold by insiders...</td>\n",
       "      <td>Google Cuts Its IPO Price Range SAN JOSE, Calif. - In a sign that Google Inc.'s initial public offering will not be as hot or big as expected, the Internet search giant slashed its estimated per-share price range and reduced the number of shares to be sold by insiders...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20371</th>\n",
       "      <td>3</td>\n",
       "      <td>FOCUS: Santander Says HBOS Counterbid To Face Problems</td>\n",
       "      <td>LONDON (Dow Jones)--Banco Santander Central Hispano SA (STD), the Spanish bank planning to buy UK lender Abbey National PLC (ANBA), Monday attacked its potential domestic</td>\n",
       "      <td>FOCUS: Santander Says HBOS Counterbid To Face Problems LONDON (Dow Jones)--Banco Santander Central Hispano SA (STD), the Spanish bank planning to buy UK lender Abbey National PLC (ANBA), Monday attacked its potential domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108151</th>\n",
       "      <td>4</td>\n",
       "      <td>HP Revises Cluster Plans</td>\n",
       "      <td>HP (Quote, Chart) is dropping its efforts to port some Tru64 Unix products to HP-UX with the help of storage player Veritas . The two companies announced a multi-year agreement Thursday that finds HP #39;s sales</td>\n",
       "      <td>HP Revises Cluster Plans HP (Quote, Chart) is dropping its efforts to port some Tru64 Unix products to HP-UX with the help of storage player Veritas . The two companies announced a multi-year agreement Thursday that finds HP #39;s sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class Index                                                   Title  \\\n",
       "71787             3            BBC set for major shake-up, claims newspaper   \n",
       "67218             3                                Marsh averts cash crunch   \n",
       "54066             2                Jeter, Yankees Look to Take Control (AP)   \n",
       "7168              4                                Flying the Sun to Safety   \n",
       "29618             3                Stocks Seen Flat as Nortel and Oil Weigh   \n",
       "101425            2       Inter Milan seeks redemption win against Juventus   \n",
       "20441             3                            Saudi Arabia cuts oil prices   \n",
       "2662              1                         Google Cuts Its IPO Price Range   \n",
       "20371             3  FOCUS: Santander Says HBOS Counterbid To Face Problems   \n",
       "108151            4                                HP Revises Cluster Plans   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                     Description  \\\n",
       "71787                                                                                                        London - The British Broadcasting Corporation, the world #39;s biggest public broadcaster, is to cut almost a quarter of its 28 000-strong workforce, in the biggest shake-up in its 82-year history, The Times newspaper in London said on Monday.   \n",
       "67218                                                                                                                                                                                                      Embattled insurance broker #39;s banks agree to waive clause that may have prevented access to credit. NEW YORK (Reuters) - Marsh  amp; McLennan Cos.   \n",
       "54066                                                                                                                                                                                                                               AP - Derek Jeter turned a season that started with a terrible slump into one of the best in his accomplished 10-year career.   \n",
       "7168                                                                                                                                                                                                        When the Genesis capsule comes back to Earth with its samples of the sun, helicopter pilots will be waiting for it, ready to snag it out of the sky.   \n",
       "29618    NEW YORK (Reuters) - U.S. stocks were set to open near  unchanged on Thursday after a warning from technology  bellwether Nortel Networks Corp. &lt;A HREF=\"http://www.investor.reuters.com/FullQuote.aspx?ticker=NT.N target=/stocks/quickinfo/fullquote\"&gt;NT.N&lt;/A&gt; dimmed hopes, while  stubbornly high oil prices also weighed on sentiment.   \n",
       "101425                                                                                                                         It is early in the season for a decisive match, yet Inter Milan-Juventus on Sunday is shaping up as exactly that. Serie A leader Juventus stands 15 points ahead of Inter, but both teams see the meeting as key to their season.   \n",
       "20441                                                                                                                                                                   Oil prices eased yesterday as top world exporter Saudi Arabia slashed prices for its westbound crude sales in an effort to shift the large volumes it is offering to cool world markets.   \n",
       "2662                                                                                                             SAN JOSE, Calif. - In a sign that Google Inc.'s initial public offering will not be as hot or big as expected, the Internet search giant slashed its estimated per-share price range and reduced the number of shares to be sold by insiders...   \n",
       "20371                                                                                                                                                                                LONDON (Dow Jones)--Banco Santander Central Hispano SA (STD), the Spanish bank planning to buy UK lender Abbey National PLC (ANBA), Monday attacked its potential domestic    \n",
       "108151                                                                                                                                      HP (Quote, Chart) is dropping its efforts to port some Tru64 Unix products to HP-UX with the help of storage player Veritas . The two companies announced a multi-year agreement Thursday that finds HP #39;s sales    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                     text  \n",
       "71787                                                                                                    BBC set for major shake-up, claims newspaper London - The British Broadcasting Corporation, the world #39;s biggest public broadcaster, is to cut almost a quarter of its 28 000-strong workforce, in the biggest shake-up in its 82-year history, The Times newspaper in London said on Monday.  \n",
       "67218                                                                                                                                                                                                                      Marsh averts cash crunch Embattled insurance broker #39;s banks agree to waive clause that may have prevented access to credit. NEW YORK (Reuters) - Marsh  amp; McLennan Cos.  \n",
       "54066                                                                                                                                                                                                                               Jeter, Yankees Look to Take Control (AP) AP - Derek Jeter turned a season that started with a terrible slump into one of the best in his accomplished 10-year career.  \n",
       "7168                                                                                                                                                                                                                        Flying the Sun to Safety When the Genesis capsule comes back to Earth with its samples of the sun, helicopter pilots will be waiting for it, ready to snag it out of the sky.  \n",
       "29618   Stocks Seen Flat as Nortel and Oil Weigh  NEW YORK (Reuters) - U.S. stocks were set to open near  unchanged on Thursday after a warning from technology  bellwether Nortel Networks Corp. &lt;A HREF=\"http://www.investor.reuters.com/FullQuote.aspx?ticker=NT.N target=/stocks/quickinfo/fullquote\"&gt;NT.N&lt;/A&gt; dimmed hopes, while  stubbornly high oil prices also weighed on sentiment.  \n",
       "101425                                                                                                                Inter Milan seeks redemption win against Juventus It is early in the season for a decisive match, yet Inter Milan-Juventus on Sunday is shaping up as exactly that. Serie A leader Juventus stands 15 points ahead of Inter, but both teams see the meeting as key to their season.  \n",
       "20441                                                                                                                                                                               Saudi Arabia cuts oil prices Oil prices eased yesterday as top world exporter Saudi Arabia slashed prices for its westbound crude sales in an effort to shift the large volumes it is offering to cool world markets.  \n",
       "2662                                                                                                                      Google Cuts Its IPO Price Range SAN JOSE, Calif. - In a sign that Google Inc.'s initial public offering will not be as hot or big as expected, the Internet search giant slashed its estimated per-share price range and reduced the number of shares to be sold by insiders...  \n",
       "20371                                                                                                                                                                  FOCUS: Santander Says HBOS Counterbid To Face Problems LONDON (Dow Jones)--Banco Santander Central Hispano SA (STD), the Spanish bank planning to buy UK lender Abbey National PLC (ANBA), Monday attacked its potential domestic   \n",
       "108151                                                                                                                                                      HP Revises Cluster Plans HP (Quote, Chart) is dropping its efforts to port some Tru64 Unix products to HP-UX with the help of storage player Veritas . The two companies announced a multi-year agreement Thursday that finds HP #39;s sales   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리 뭐할지? 확인용\n",
    "sample = train_df.sample(10)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "456e1e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "\n",
    "# 0. 4분의 1만 쓰겠다!\n",
    "train_df = train_df.sample(frac=0.25, random_state=42)\n",
    "\n",
    "# 1. 빈값\n",
    "train_df = train_df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "# 2. etc...\n",
    "def clean_text(line):\n",
    "    line = html.unescape(line) # tag 복구\n",
    "    line = line.replace(\"#39;\", \"'\")   # 작은 따옴표\n",
    "    line = line.replace(\"#36;\", \"$\")   # 달러\n",
    "    line = line.replace(\"amp;\", \"&\")   # &\n",
    "    line = re.sub('<.*?>', '', line) # delete html tag\n",
    "    line = re.sub(r'http\\S+', '', line) # delete html links\n",
    "    line = ' '.join(line.split()) # 공백 제거\n",
    "    line = re.sub(r'\\((tm|r|TM|R)\\)', '', line) # 상표 기호 제거\n",
    "    line = re.sub(r'\\\\', ' ', line) # 역슬래시\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f65e37b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before cleaning:  Manugistics Group Inc. disclosed Monday that it fired its president, as the maker of business software tries to reverse slipping sales, rising costs and a falling stock price. &lt;BR&gt;&lt;FONT face=\"verdana,MS Sans Serif,arial,helvetica\" size=\"-2\"\\ color=\"#666666\"&gt;&lt;B&gt;-The Washington Post&lt;/B&gt;&lt;/FONT&gt;\n",
      "after cleaning:  Manugistics Group Inc. disclosed Monday that it fired its president, as the maker of business software tries to reverse slipping sales, rising costs and a falling stock price. -The Washington Post\n"
     ]
    }
   ],
   "source": [
    "# output????\n",
    "test_sentence = train_df['Description'].iloc[10]\n",
    "tokens = clean_text(test_sentence)\n",
    "print(\"before cleaning: \", test_sentence)\n",
    "print(\"after cleaning: \", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86d61f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적용\n",
    "train_df['text'] = train_df['text'].apply(clean_text)\n",
    "test_df['text'] = test_df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eafe24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class Index\n",
       "2    0.252000\n",
       "4    0.250933\n",
       "1    0.249067\n",
       "3    0.248000\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Class Index'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c04cc678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    30000.000000\n",
       "mean       231.333667\n",
       "std         61.281713\n",
       "min         48.000000\n",
       "25%        194.000000\n",
       "50%        229.000000\n",
       "75%        261.000000\n",
       "max        976.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 길이 확인\n",
    "train_df['text'].str.len().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4218b021",
   "metadata": {},
   "source": [
    "## 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de3f0ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer load\n",
    "MODEL_NAME = \"bert-base-uncased\" # 대소문자 -> 소문자 / 기본 모델\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    token=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "678e2e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before tokenizer:  Marsh averts cash crunch Embattled insurance broker 's banks agree to waive clause that may have prevented access to credit. NEW YORK (Reuters) - Marsh & McLennan Cos.\n",
      "after tokenizer:  ['marsh', 'ave', '##rts', 'cash', 'crunch', 'em', '##bat', '##tled', 'insurance', 'broker', \"'\", 's', 'banks', 'agree', 'to', 'wai', '##ve', 'clause', 'that', 'may', 'have', 'prevented', 'access', 'to', 'credit', '.', 'new', 'york', '(', 'reuters', ')', '-', 'marsh', '&', 'mc', '##len', '##nan', 'co', '##s', '.']\n",
      "\n",
      "after encodings:  [101, 9409, 13642, 21217, 5356, 24514, 7861, 14479, 14782, 5427, 20138, 1005, 1055, 5085, 5993, 2000, 23701, 3726, 11075, 2008, 2089, 2031, 8729, 3229, 2000, 4923, 1012, 2047, 2259, 1006, 26665, 1007, 1011, 9409, 1004, 11338, 7770, 7229, 2522, 2015, 1012, 102]\n",
      "convert to ids:  [9409, 13642, 21217, 5356, 24514, 7861, 14479, 14782, 5427, 20138, 1005, 1055, 5085, 5993, 2000, 23701, 3726, 11075, 2008, 2089, 2031, 8729, 3229, 2000, 4923, 1012, 2047, 2259, 1006, 26665, 1007, 1011, 9409, 1004, 11338, 7770, 7229, 2522, 2015, 1012]\n",
      "[CLS] marsh averts cash crunch embattled insurance broker ' s banks agree to waive clause that may have prevented access to credit. new york ( reuters ) - marsh & mclennan cos. [SEP]\n",
      "marsh averts cash crunch embattled insurance broker ' s banks agree to waive clause that may have prevented access to credit. new york ( reuters ) - marsh & mclennan cos.\n",
      "\n",
      "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']\n",
      "[100, 102, 0, 101, 103]\n"
     ]
    }
   ],
   "source": [
    "# output????\n",
    "test_sentence = train_df['text'].iloc[1]\n",
    "tokens = tokenizer.tokenize(test_sentence) # 단순 단어 쪼개기\n",
    "print(\"before tokenizer: \", test_sentence)\n",
    "print(\"after tokenizer: \", tokens)\n",
    "\n",
    "inputs = tokenizer.convert_tokens_to_ids(tokens) # token -> vocab ids\n",
    "\n",
    "train_encodings = tokenizer(\n",
    "    test_sentence, \n",
    "    # return_tensors=\"pt\" # pytorch tensor\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"after encodings: \", train_encodings['input_ids']) # CLS SEP token added\n",
    "print(\"convert to ids: \", inputs)\n",
    "print(tokenizer.decode(train_encodings['input_ids']))\n",
    "print(tokenizer.decode(inputs))\n",
    "print()\n",
    "print(tokenizer.all_special_tokens)\n",
    "print(tokenizer.all_special_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7309c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_labels, texts = [train_df[col].tolist() for col in ['Class Index', 'text']]\n",
    "train_encodings = tokenizer(\n",
    "    texts,\n",
    "    padding=\"max_length\", # model 최대길이 BERT = 512\n",
    "    truncation=True, # cutting\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# test\n",
    "test_labels, texts = [test_df[col].tolist() for col in ['Class Index', 'text']]\n",
    "test_encodings = tokenizer(\n",
    "    texts,\n",
    "    padding=\"max_length\", # model 최대길이 BERT = 512\n",
    "    truncation=True, # cutting\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fabba215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data Loader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels, is_train=True):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.is_train = is_train\n",
    "        \n",
    "    #  데이터 전체 길이  \n",
    "    def __len__(self):\n",
    "        return len(self.labels) # or encodings['input_ids']\n",
    "    \n",
    "    # 어떻게 반환?\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.encodings['input_ids'][idx]\n",
    "        if self.is_train:\n",
    "            label = torch.tensor(self.labels[idx] - 1, dtype = torch.long) # 0 ~ 3\n",
    "            return input_ids, label # train 만 class index 값 넘기기\n",
    "        else:\n",
    "            return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14cb7ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = 0) # padding idx = 0 이라고 알려줌\n",
    "        self.lstm = nn.LSTM(\n",
    "            embed_dim, \n",
    "            hidden_dim, \n",
    "            batch_first=True,  # 입력 순서를 (Batch size, 문장 길이, 단어 특징) 로 맞추기 위해????\n",
    "            dropout=dropout) \n",
    "        self.fc = nn.Linear(\n",
    "            hidden_dim,\n",
    "            output_dim) # label 4 개\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, line): # 실제 실행?\n",
    "        embedded = self.dropout(self.embedding(line)) # 빈칸 반환 -> 추론 \n",
    "        output, _ = self.lstm(embedded)\n",
    "        pooled_output, _ = torch.max(output, dim=1) # 마지막 값 뽑는거에서 가장 큰 값 뽑는 거로 바꿈 -> 가장 .. 신호가 강한 거..?      \n",
    "        return self.fc(self.dropout(pooled_output)) # fc 층에 통과시켜서 label 4개중에 어디에 속할지 점수 계산해서 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8439b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "LR = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0eb67f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkyhkjs2002\u001b[0m (\u001b[33mpro-nlp-generationfornlp-nlp-13\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/yhkim/news-classification/src/exac/wandb/run-20260115_090823-mudxrcp9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimyoungh/news-classification/runs/mudxrcp9' target=\"_blank\">electric-feather-8</a></strong> to <a href='https://wandb.ai/kimyoungh/news-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimyoungh/news-classification' target=\"_blank\">https://wandb.ai/kimyoungh/news-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimyoungh/news-classification/runs/mudxrcp9' target=\"_blank\">https://wandb.ai/kimyoungh/news-classification/runs/mudxrcp9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wandb\n",
    "import wandb\n",
    "run = wandb.init(\n",
    "    entity=\"kimyoungh\",\n",
    "    project=\"news-classification\",\n",
    "    config={\n",
    "        \"learning_rate\": LR,\n",
    "        \"architecture\": \"LSTM\",\n",
    "        \"dataset\": \"AG\",\n",
    "        \"epochs\": EPOCHS,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "233e47f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([  101,  4035,  2275,  2005,  2350,  6073,  1011,  2039,  1010,  4447,\n",
      "         3780,  2414,  1011,  1996,  2329,  5062,  3840,  1010,  1996,  2088,\n",
      "         1005,  1055,  5221,  2270, 11995,  1010,  2003,  2000,  3013,  2471,\n",
      "         1037,  4284,  1997,  2049,  2654,  2199,  1011,  2844, 14877,  1010,\n",
      "         1999,  1996,  5221,  6073,  1011,  2039,  1999,  2049,  6445,  1011,\n",
      "         2095,  2381,  1010,  1996,  2335,  3780,  1999,  2414,  2056,  2006,\n",
      "         6928,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]), tensor(2))\n",
      "(tensor([  101, 10069,  2005,  1056,  1050, 11550,  2044,  7566,  9209,  5052,\n",
      "         3667,  2012,  6769,  2047,  8095,  2360,  2027,  2024,  1005,  9364,\n",
      "         1005,  2044,  7566,  2007, 16654,  6687,  3813,  2976,  9587, 24848,\n",
      "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]), tensor(2))\n"
     ]
    }
   ],
   "source": [
    "# dataset dataloader\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = CustomDataset(train_encodings, train_labels, is_train=True)\n",
    "test_dataset = CustomDataset(test_encodings, test_labels, is_train=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# 걍 찍어보기 -> 최대 길이에 맞춰서 padding 값으로 0\n",
    "for x in train_dataset:\n",
    "    print(x)\n",
    "    break\n",
    "\n",
    "for x in test_dataset:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dbb55ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 시작! (Device: cuda)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/yhkim/.venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Train Loss: 0.590 | Train Acc: 77.60% | Val Loss: 0.339 | Val Acc: 88.14%\n",
      "Epoch: 02 | Train Loss: 0.296 | Train Acc: 89.99% | Val Loss: 0.302 | Val Acc: 89.75%\n",
      "Epoch: 03 | Train Loss: 0.222 | Train Acc: 92.43% | Val Loss: 0.309 | Val Acc: 89.68%\n",
      "Epoch: 04 | Train Loss: 0.173 | Train Acc: 94.04% | Val Loss: 0.330 | Val Acc: 89.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Train Loss: 0.142 | Train Acc: 95.12% | Val Loss: 0.351 | Val Acc: 89.83%\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_acc</td><td>▁▆▇██</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>val_acc</td><td>▁█▇██</td></tr><tr><td>val_loss</td><td>▆▁▂▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>train_acc</td><td>0.9512</td></tr><tr><td>train_loss</td><td>0.14196</td></tr><tr><td>val_acc</td><td>0.89829</td></tr><tr><td>val_loss</td><td>0.35061</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">electric-feather-8</strong> at: <a href='https://wandb.ai/kimyoungh/news-classification/runs/mudxrcp9' target=\"_blank\">https://wandb.ai/kimyoungh/news-classification/runs/mudxrcp9</a><br> View project at: <a href='https://wandb.ai/kimyoungh/news-classification' target=\"_blank\">https://wandb.ai/kimyoungh/news-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260115_090823-mudxrcp9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "EMBED_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 4 # class index 값 \n",
    "DROPOUT = 0.3 # prevent overfitting \n",
    "USE_WANDB = True\n",
    "\n",
    "model = LSTMClassifier(\n",
    "    vocab_size=tokenizer.vocab_size, \n",
    "    embed_dim=EMBED_DIM, \n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=OUTPUT_DIM, \n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_and_eval(model, train_loader, test_loader, optimizer, criterion, device, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        total_samples = 0\n",
    "        for inputs, label in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            # 이전 배치 초기화\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 예...측?\n",
    "            output = model(inputs)\n",
    "            \n",
    "            # loss function\n",
    "            loss = criterion(output, label)\n",
    "            acc = (output.argmax(1) == label).float().mean()\n",
    "            \n",
    "            # 역전파 - 기울기 계산\n",
    "            loss.backward()\n",
    "            # 가중치 업데이트 \n",
    "            optimizer.step()\n",
    "            \n",
    "            # ?\n",
    "            batch_size = label.size(0) # 현재 배치 샘플 수?\n",
    "            epoch_loss += loss.item() * batch_size # 배치 사이즈 곱해서 샘플 기준 합\n",
    "            epoch_acc += acc.item() * batch_size # \n",
    "            total_samples += batch_size\n",
    "            \n",
    "        avg_loss = epoch_loss / total_samples\n",
    "        avg_acc = epoch_acc / total_samples\n",
    "        \n",
    "        # eval\n",
    "        model.eval()\n",
    "        val_samples = 0\n",
    "        val_epoch_loss = 0\n",
    "        val_epoch_acc = 0\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for inputs, label in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                label = label.to(device)\n",
    "                \n",
    "                output = model(inputs)\n",
    "                loss = criterion(output, label)\n",
    "                acc = (output.argmax(1) == label).float().mean()\n",
    "                \n",
    "                batch_size = label.size(0)\n",
    "                val_epoch_loss += loss.item() * batch_size\n",
    "                val_epoch_acc += acc.item() * batch_size\n",
    "                val_samples += batch_size\n",
    "                    \n",
    "            val_loss = val_epoch_loss / val_samples\n",
    "            val_acc = val_epoch_acc / val_samples \n",
    "        \n",
    "        print(f'Epoch: {epoch+1:02} | Train Loss: {avg_loss:.3f} | Train Acc: {avg_acc*100:.2f}% | Val Loss: {val_loss:.3f} | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "        if USE_WANDB:\n",
    "            run.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": avg_loss, \"train_acc\": avg_acc,\n",
    "                \"val_loss\": val_loss, \"val_acc\": val_acc,\n",
    "                # \"save_\" # step saving\n",
    "            })\n",
    "\n",
    "print(f\"학습 시작! (Device: {device})\")\n",
    "train_and_eval(model, train_loader, test_loader, optimizer, criterion, device, EPOCHS)\n",
    "\n",
    "run.finish() # wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "413413cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BERT model with out-layer\n",
    "from transformers import BertForSequenceClassification\n",
    "bert_model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=4) # 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2b1c696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 109485316, trainable: 109485316, fixed: 0\n"
     ]
    }
   ],
   "source": [
    "# 모델 파라미터 수?\n",
    "def total_trainable_fixed(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_fixed_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "    return total_params, total_trainable_params, total_fixed_params\n",
    "\n",
    "x, y, z = total_trainable_fixed(bert_model)\n",
    "print(f\"total: {x}, trainable: {y}, fixed: {z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c40322b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이름: bert.embeddings.word_embeddings.weight | 크기: torch.Size([30522, 768])\n",
      "이름: bert.embeddings.position_embeddings.weight | 크기: torch.Size([512, 768])\n",
      "이름: bert.embeddings.token_type_embeddings.weight | 크기: torch.Size([2, 768])\n",
      "이름: bert.embeddings.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.embeddings.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.0.attention.self.query.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.0.attention.self.query.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.0.attention.self.key.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.0.attention.self.key.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.0.attention.self.value.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.0.attention.self.value.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.0.attention.output.dense.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.0.attention.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.0.attention.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.0.attention.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.0.intermediate.dense.weight | 크기: torch.Size([3072, 768])\n",
      "이름: bert.encoder.layer.0.intermediate.dense.bias | 크기: torch.Size([3072])\n",
      "이름: bert.encoder.layer.0.output.dense.weight | 크기: torch.Size([768, 3072])\n",
      "이름: bert.encoder.layer.0.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.0.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.0.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.1.attention.self.query.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.1.attention.self.query.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.1.attention.self.key.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.1.attention.self.key.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.1.attention.self.value.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.1.attention.self.value.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.1.attention.output.dense.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.1.attention.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.1.attention.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.1.attention.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.1.intermediate.dense.weight | 크기: torch.Size([3072, 768])\n",
      "이름: bert.encoder.layer.1.intermediate.dense.bias | 크기: torch.Size([3072])\n",
      "이름: bert.encoder.layer.1.output.dense.weight | 크기: torch.Size([768, 3072])\n",
      "이름: bert.encoder.layer.1.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.1.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.1.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.2.attention.self.query.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.2.attention.self.query.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.2.attention.self.key.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.2.attention.self.key.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.2.attention.self.value.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.2.attention.self.value.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.2.attention.output.dense.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.2.attention.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.2.attention.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.2.attention.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.2.intermediate.dense.weight | 크기: torch.Size([3072, 768])\n",
      "이름: bert.encoder.layer.2.intermediate.dense.bias | 크기: torch.Size([3072])\n",
      "이름: bert.encoder.layer.2.output.dense.weight | 크기: torch.Size([768, 3072])\n",
      "이름: bert.encoder.layer.2.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.2.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.2.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.3.attention.self.query.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.3.attention.self.query.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.3.attention.self.key.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.3.attention.self.key.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.3.attention.self.value.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.3.attention.self.value.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.3.attention.output.dense.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.3.attention.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.3.attention.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.3.attention.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.3.intermediate.dense.weight | 크기: torch.Size([3072, 768])\n",
      "이름: bert.encoder.layer.3.intermediate.dense.bias | 크기: torch.Size([3072])\n",
      "이름: bert.encoder.layer.3.output.dense.weight | 크기: torch.Size([768, 3072])\n",
      "이름: bert.encoder.layer.3.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.3.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.3.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.4.attention.self.query.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.4.attention.self.query.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.4.attention.self.key.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.4.attention.self.key.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.4.attention.self.value.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.4.attention.self.value.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.4.attention.output.dense.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.4.attention.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.4.attention.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.4.attention.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.4.intermediate.dense.weight | 크기: torch.Size([3072, 768])\n",
      "이름: bert.encoder.layer.4.intermediate.dense.bias | 크기: torch.Size([3072])\n",
      "이름: bert.encoder.layer.4.output.dense.weight | 크기: torch.Size([768, 3072])\n",
      "이름: bert.encoder.layer.4.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.4.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.4.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.5.attention.self.query.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.5.attention.self.query.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.5.attention.self.key.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.5.attention.self.key.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.5.attention.self.value.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.5.attention.self.value.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.5.attention.output.dense.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.5.attention.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.5.attention.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.5.attention.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.5.intermediate.dense.weight | 크기: torch.Size([3072, 768])\n",
      "이름: bert.encoder.layer.5.intermediate.dense.bias | 크기: torch.Size([3072])\n",
      "이름: bert.encoder.layer.5.output.dense.weight | 크기: torch.Size([768, 3072])\n",
      "이름: bert.encoder.layer.5.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.5.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.5.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.6.attention.self.query.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.6.attention.self.query.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.6.attention.self.key.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.6.attention.self.key.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.6.attention.self.value.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.6.attention.self.value.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.6.attention.output.dense.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.6.attention.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.6.attention.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.6.attention.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.6.intermediate.dense.weight | 크기: torch.Size([3072, 768])\n",
      "이름: bert.encoder.layer.6.intermediate.dense.bias | 크기: torch.Size([3072])\n",
      "이름: bert.encoder.layer.6.output.dense.weight | 크기: torch.Size([768, 3072])\n",
      "이름: bert.encoder.layer.6.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.6.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.6.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.7.attention.self.query.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.7.attention.self.query.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.7.attention.self.key.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.7.attention.self.key.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.7.attention.self.value.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.7.attention.self.value.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.7.attention.output.dense.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.7.attention.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.7.attention.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.7.attention.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.7.intermediate.dense.weight | 크기: torch.Size([3072, 768])\n",
      "이름: bert.encoder.layer.7.intermediate.dense.bias | 크기: torch.Size([3072])\n",
      "이름: bert.encoder.layer.7.output.dense.weight | 크기: torch.Size([768, 3072])\n",
      "이름: bert.encoder.layer.7.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.7.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.7.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.8.attention.self.query.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.8.attention.self.query.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.8.attention.self.key.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.8.attention.self.key.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.8.attention.self.value.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.8.attention.self.value.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.8.attention.output.dense.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.8.attention.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.8.attention.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.8.attention.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.8.intermediate.dense.weight | 크기: torch.Size([3072, 768])\n",
      "이름: bert.encoder.layer.8.intermediate.dense.bias | 크기: torch.Size([3072])\n",
      "이름: bert.encoder.layer.8.output.dense.weight | 크기: torch.Size([768, 3072])\n",
      "이름: bert.encoder.layer.8.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.8.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.8.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.9.attention.self.query.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.9.attention.self.query.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.9.attention.self.key.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.9.attention.self.key.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.9.attention.self.value.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.9.attention.self.value.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.9.attention.output.dense.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.9.attention.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.9.attention.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.9.attention.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.9.intermediate.dense.weight | 크기: torch.Size([3072, 768])\n",
      "이름: bert.encoder.layer.9.intermediate.dense.bias | 크기: torch.Size([3072])\n",
      "이름: bert.encoder.layer.9.output.dense.weight | 크기: torch.Size([768, 3072])\n",
      "이름: bert.encoder.layer.9.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.9.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.9.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.10.attention.self.query.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.10.attention.self.query.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.10.attention.self.key.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.10.attention.self.key.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.10.attention.self.value.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.10.attention.self.value.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.10.attention.output.dense.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.10.attention.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.10.attention.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.10.attention.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.10.intermediate.dense.weight | 크기: torch.Size([3072, 768])\n",
      "이름: bert.encoder.layer.10.intermediate.dense.bias | 크기: torch.Size([3072])\n",
      "이름: bert.encoder.layer.10.output.dense.weight | 크기: torch.Size([768, 3072])\n",
      "이름: bert.encoder.layer.10.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.10.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.10.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.11.attention.self.query.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.11.attention.self.query.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.11.attention.self.key.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.11.attention.self.key.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.11.attention.self.value.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.11.attention.self.value.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.11.attention.output.dense.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.encoder.layer.11.attention.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.11.attention.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.11.attention.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.11.intermediate.dense.weight | 크기: torch.Size([3072, 768])\n",
      "이름: bert.encoder.layer.11.intermediate.dense.bias | 크기: torch.Size([3072])\n",
      "이름: bert.encoder.layer.11.output.dense.weight | 크기: torch.Size([768, 3072])\n",
      "이름: bert.encoder.layer.11.output.dense.bias | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.11.output.LayerNorm.weight | 크기: torch.Size([768])\n",
      "이름: bert.encoder.layer.11.output.LayerNorm.bias | 크기: torch.Size([768])\n",
      "이름: bert.pooler.dense.weight | 크기: torch.Size([768, 768])\n",
      "이름: bert.pooler.dense.bias | 크기: torch.Size([768])\n",
      "이름: classifier.weight | 크기: torch.Size([4, 768])\n",
      "이름: classifier.bias | 크기: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# 모델 params\n",
    "for name, param in bert_model.named_parameters():\n",
    "    print(f\"이름: {name} | 크기: {param.size()}\")\n",
    "    \n",
    "# 이름: classifier.weight | 크기: torch.Size([4, 768])\n",
    "# 이름: classifier.bias | 크기: torch.Size([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d431c652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 109485316, trainable: 0, fixed: 109485316\n"
     ]
    }
   ],
   "source": [
    "# 모든 layer 에 대해 freeze 수행\n",
    "for params in bert_model.parameters():\n",
    "    params.requires_grad = False\n",
    "\n",
    "x, y, z = total_trainable_fixed(bert_model)\n",
    "print(f\"total: {x}, trainable: {y}, fixed: {z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb104040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.weight\n",
      "classifier.bias\n",
      "total: 109485316, trainable: 3076, fixed: 109482240\n"
     ]
    }
   ],
   "source": [
    "# 분류기? classifier 만 학습 가능 상태\n",
    "for name, params in bert_model.named_parameters():\n",
    "    if 'classifier' in name:\n",
    "        print(name)\n",
    "        params.requires_grad = True\n",
    "\n",
    "x, y, z = total_trainable_fixed(bert_model)\n",
    "print(f\"total: {x}, trainable: {y}, fixed: {z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc4721f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train_and_eval() takes 6 positional arguments but 7 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m bert_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_and_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbert_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: train_and_eval() takes 6 positional arguments but 7 were given"
     ]
    }
   ],
   "source": [
    "bert_model = bert_model.to(device)\n",
    "train_and_eval(bert_model, train_loader, test_loader, optimizer, criterion, device, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
